
# ğŸ¤– MultiRAG Chatbot

A **Multi-Document Retrieval-Augmented Generation (RAG) Chatbot** built with **LangChain v0.2+, Groq LLM, and Chroma Vector DB**.  
This chatbot allows users to upload and query multiple files (PDFs, DOCX, CSV, PPT, Excel, TXT, RTF, ODT, etc.) and get **precise, context-aware answers** in real time.

---

## âœ¨ Features
- ğŸ“‚ **Multi-format Document Uploads** â€” PDF, DOC/DOCX, PPT, Excel, TXT, CSV, RTF, ODT.
- âš¡ **Groq-Powered LLM** â€” Uses **Groqâ€™s LLaMA-3.1** for fast, context-rich responses.
- ğŸ—„ï¸ **Vector Database** â€” Stores embeddings with **Chroma** for efficient retrieval.
- ğŸ“‘ **Chunking & Indexing** â€” Smart text splitting for better answer quality.
- ğŸš€ **Large File Support** â€” Handles files up to **200MB** with background processing.
- ğŸ§¹ **Data Management** â€” `/clear` API wipes all processed data in one click.
- ğŸŒ **REST API + Web UI** â€” Flask backend, optional frontend in `templates/`.

---

## ğŸ› ï¸ Tech Stack
- **Backend:** Python (Flask)
- **LLM:** Groq LLaMA (via `langchain_groq`)
- **Vector DB:** Chroma
- **Embeddings:** HuggingFace (`all-MiniLM-L6-v2`)
- **File Parsing:** pdfplumber, PyMuPDF, python-docx, openpyxl, python-pptx
- **Other Tools:** dotenv, threading for background tasks

---

## ğŸ“‚ Project Structure
```

ğŸ“¦ Multi\_RAG\_Chatbot
â”£ ğŸ“‚ uploads/          # Uploaded raw files
â”£ ğŸ“‚ processed/        # Processed chunks & vector store
â”£ ğŸ“‚ templates/        # Optional frontend (index.html)
â”£ ğŸ“œ app.py            # Main Flask backend
â”£ ğŸ“œ requirements.txt  # Python dependencies
â”£ ğŸ“œ .env.example      # Sample environment variables
â”— ğŸ“œ README.md         # Project documentation

````

---

## âš™ï¸ Installation

### 1. Clone Repository
```bash
git clone https://github.com/vamseeswar/Multi_RAG_Chatbot.git
cd Multi_RAG_Chatbot
````

### 2. Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Setup Environment Variables

Create a `.env` file:

```ini
UPLOAD_FOLDER=uploads
PROCESSED_FOLDER=processed
CHROMA_DIR=processed/chroma_db

# Groq API
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-8b-instant
GROQ_TEMPERATURE=0.1

# RAG Settings
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
SIMILARITY_K=10
SIMILARITY_THRESHOLD=0.5
```

---

## â–¶ï¸ Running the App

```bash
python app.py
```

Server runs at **[http://localhost:5000](http://localhost:5000)**

---

## ğŸ”— API Endpoints

| Method | Endpoint              | Description              |
| ------ | --------------------- | ------------------------ |
| POST   | `/upload`             | Upload a document        |
| GET    | `/upload_status/<id>` | Check processing status  |
| POST   | `/ask`                | Query uploaded documents |
| POST   | `/clear`              | Clear all data           |
| GET    | `/health`             | Health check             |

---

## ğŸ“Š Example Workflow

1. Upload `research_paper.pdf`
2. Ask: **â€œWhat is the conclusion of the paper?â€**
3. Chatbot retrieves relevant text & responds using **Groq LLM**.

---

## ğŸš§ Future Improvements

* â¬†ï¸ Handle **500MB+ uploads** with streaming
* ğŸ‘¥ Add **multi-user session support**
* ğŸ”„ Real-time **WebSocket streaming answers**
* ğŸ¨ Enhanced UI with themes & animations

---

## ğŸ‘¨â€ğŸ’» Author

Developed by **[Vamseeswar](https://github.com/vamseeswar)**
ğŸ“Œ Repository: [Multi\_RAG\_Chatbot](https://github.com/vamseeswar/Multi_RAG_Chatbot)

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€“ free to use, modify, and distribute.

```


